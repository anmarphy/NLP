{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Transformer Functionalities"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Semantic Similarity"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\r\n",
        "import torch\r\n",
        "\r\n",
        "embedder = SentenceTransformer('paraphrase-distilroberta-base-v1') ##  SBERT paper: Sentence-BERT: Sentence Embeddings using Siamese BERT-Networks"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1618255038843
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\r\n",
        "sentences = ['I am writing this notebook on Azure Machine Learning framework',\r\n",
        "    'The first certification in AWS is the Cloud practioner']\r\n",
        "sentence_embeddings = model.encode(sentences)\r\n",
        "\r\n",
        "print(\"Sentence embeddings:\")\r\n",
        "print(sentence_embeddings) #Semantically meaningful sentence embedings\r\n",
        "#Map each sentence to a vector space such that semantically similar sentences are close"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence embeddings:\n",
            "[[-0.07435048 -0.3073893  -0.2914517  ... -0.14530991 -0.21303491\n",
            "  -0.12939769]\n",
            " [ 0.04234526 -0.06872454 -0.16243754 ... -0.55217934  0.24117126\n",
            "   0.23806   ]]\n"
          ]
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255042488
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(sentence_embeddings[0])"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 3,
          "data": {
            "text/plain": "768"
          },
          "metadata": {}
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255042654
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Corpus with example sentences\r\n",
        "corpus = ['A man is eating food.',\r\n",
        "          'A man is eating a piece of bread.',\r\n",
        "          'The girl is carrying a baby.',\r\n",
        "          'A man is riding a horse.',\r\n",
        "          'A woman is playing violin.',\r\n",
        "          'Two men pushed carts through the woods.',\r\n",
        "          'A man is riding a white horse on an enclosed ground.',\r\n",
        "          'A monkey is playing drums.',\r\n",
        "          'A cheetah is running behind its prey.'\r\n",
        "          ]\r\n",
        "corpus_embeddings = embedder.encode(corpus, convert_to_tensor=True)\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255042746
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Query sentences:\r\n",
        "queries = ['A man is eating pasta.', 'Someone in a gorilla costume is playing a set of drums.', 'A cheetah chases prey on across a field.']"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255042893
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the closest 5 sentences of the corpus for each query sentence based on cosine similarity\r\n",
        "top_k = min(5, len(corpus))\r\n",
        "for query in queries:\r\n",
        "    query_embedding = embedder.encode(query, convert_to_tensor=True)\r\n",
        "\r\n",
        "    # We use cosine-similarity and torch.topk to find the highest 5 scores\r\n",
        "    cos_scores = util.pytorch_cos_sim(query_embedding, corpus_embeddings)[0]\r\n",
        "    top_results = torch.topk(cos_scores, k=top_k)\r\n",
        "\r\n",
        "    print(\"\\n\\n======================\\n\\n\")\r\n",
        "    print(\"Query:\", query)\r\n",
        "    print(\"\\nTop 5 most similar sentences in corpus:\")\r\n",
        "\r\n",
        "    for score, idx in zip(top_results[0], top_results[1]):\r\n",
        "        print(corpus[idx], \"(Score: {:.4f})\".format(score))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: A man is eating pasta.\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A man is eating food. (Score: 0.7096)\n",
            "A man is eating a piece of bread. (Score: 0.6074)\n",
            "A man is riding a horse. (Score: 0.3360)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.3069)\n",
            "A woman is playing violin. (Score: 0.2378)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: Someone in a gorilla costume is playing a set of drums.\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A monkey is playing drums. (Score: 0.6842)\n",
            "A woman is playing violin. (Score: 0.3762)\n",
            "A man is riding a horse. (Score: 0.3079)\n",
            "A cheetah is running behind its prey. (Score: 0.2760)\n",
            "A man is eating a piece of bread. (Score: 0.2495)\n",
            "\n",
            "\n",
            "======================\n",
            "\n",
            "\n",
            "Query: A cheetah chases prey on across a field.\n",
            "\n",
            "Top 5 most similar sentences in corpus:\n",
            "A cheetah is running behind its prey. (Score: 0.7814)\n",
            "A monkey is playing drums. (Score: 0.2824)\n",
            "A man is riding a white horse on an enclosed ground. (Score: 0.2208)\n",
            "A man is riding a horse. (Score: 0.2017)\n",
            "A man is eating food. (Score: 0.1886)\n"
          ]
        }
      ],
      "execution_count": 6,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255043031
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, util\r\n",
        "model = SentenceTransformer('paraphrase-distilroberta-base-v1')\r\n",
        "\r\n",
        "# Two lists of sentences\r\n",
        "sentences1 = ['The cat sits outside',\r\n",
        "             'A man is playing guitar',\r\n",
        "             'The new movie is awesome']\r\n",
        "\r\n",
        "sentences2 = ['The dog plays in the garden',\r\n",
        "              'A woman watches TV',\r\n",
        "              'The new movie is so great']\r\n",
        "\r\n",
        "#Compute embedding for both lists\r\n",
        "embeddings1 = model.encode(sentences1, convert_to_tensor=True)\r\n",
        "embeddings2 = model.encode(sentences2, convert_to_tensor=True)\r\n",
        "\r\n",
        "#Compute cosine-similarits\r\n",
        "cosine_scores = util.pytorch_cos_sim(embeddings1, embeddings2)\r\n",
        "\r\n",
        "#Output the pairs with their score\r\n",
        "for i in range(len(sentences1)):\r\n",
        "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences1[i], sentences2[i], cosine_scores[i][i]))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The cat sits outside \t\t The dog plays in the garden \t\t Score: 0.4579\n",
            "A man is playing guitar \t\t A woman watches TV \t\t Score: 0.1759\n",
            "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9283\n"
          ]
        }
      ],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255046162
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cosine_scores"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 8,
          "data": {
            "text/plain": "tensor([[ 0.4579,  0.1059,  0.1447],\n        [ 0.1239,  0.1759, -0.0344],\n        [ 0.1696,  0.1313,  0.9283]])"
          },
          "metadata": {}
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255046337
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Name Entity Recognition"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\r\n",
        "from transformers import pipeline"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255046490
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"dslim/bert-base-NER\")\r\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"dslim/bert-base-NER\")"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255050295
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer)\r\n",
        "# example1='Hugging Face Inc. is a company based in New York City. \"\\\" Its headquarters are in DUMBO, therefore very close to the Manhattan Bridge which is visible from the window.'\r\n",
        "example1='Coursera Inc is an American massive open online course provider founded in 2012 by Stanford University computer science professors Andrew Ng and Daphne Koller.'"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255050393
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ner_results = nlp(example1)\r\n",
        "ner_results"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "[{'word': 'Course',\n  'score': 0.9995938539505005,\n  'entity': 'B-ORG',\n  'index': 1},\n {'word': '##ra', 'score': 0.9989863038063049, 'entity': 'I-ORG', 'index': 2},\n {'word': 'Inc', 'score': 0.9994171857833862, 'entity': 'I-ORG', 'index': 3},\n {'word': 'American',\n  'score': 0.9992867708206177,\n  'entity': 'B-MISC',\n  'index': 6},\n {'word': 'Stanford',\n  'score': 0.9990172982215881,\n  'entity': 'B-ORG',\n  'index': 16},\n {'word': 'University',\n  'score': 0.9960840344429016,\n  'entity': 'I-ORG',\n  'index': 17},\n {'word': 'Andrew',\n  'score': 0.9997637867927551,\n  'entity': 'B-PER',\n  'index': 21},\n {'word': 'Ng', 'score': 0.999763548374176, 'entity': 'I-PER', 'index': 22},\n {'word': 'Daphne',\n  'score': 0.9996672868728638,\n  'entity': 'B-PER',\n  'index': 24},\n {'word': 'Ko', 'score': 0.9997257590293884, 'entity': 'I-PER', 'index': 25},\n {'word': '##ller',\n  'score': 0.9985135793685913,\n  'entity': 'I-PER',\n  'index': 26}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255050553
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentiment Analysis"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp2 = pipeline(\"sentiment-analysis\")\r\n",
        "sent_analysis=nlp2(example1)"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255052732
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_analysis"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": "[{'label': 'POSITIVE', 'score': 0.9041023850440979}]"
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255052895
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Key word extraction"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example1"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "'Coursera Inc is an American massive open online course provider founded in 2012 by Stanford University computer science professors Andrew Ng and Daphne Koller.'"
          },
          "metadata": {}
        }
      ],
      "execution_count": 15,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255053054
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from rake_nltk import Rake\r\n",
        "r = Rake() # Uses stopwords for english from NLTK, and all puntuation characters.\r\n",
        "r.extract_keywords_from_text(example1)\r\n",
        "r.get_ranked_phrases() # To get keyword phrases ranked highest to lowest."
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "['stanford university computer science professors andrew ng',\n 'american massive open online course provider founded',\n 'daphne koller',\n 'coursera inc',\n '2012']"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255053510
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Coreference Resolution"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your usual SpaCy model (one of SpaCy English models)\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255154731
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import neuralcoref\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/anaconda/envs/azureml_py36/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: spacy.tokens.span.Span size changed, may indicate binary incompatibility. Expected 72 from C header, got 80 from PyObject\n",
            "  return f(*args, **kwds)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "<spacy.lang.en.English at 0x7f76d30a8f98>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1618255156100
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "coref = neuralcoref.NeuralCoref(nlp.vocab)\n",
        "nlp.add_pipe(coref, name='neuralcoref')\n",
        "\n",
        "# You're done. You can now use NeuralCoref the same way you usually manipulate a SpaCy document and it's annotations.\n",
        "doc = nlp(u'My sister has a dog. She loves him.')\n"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "[E007] 'neuralcoref' already exists in pipeline. Existing names: ['tagger', 'parser', 'ner', 'neuralcoref']",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5555aec81ea2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcoref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuralcoref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNeuralCoref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neuralcoref'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# You're done. You can now use NeuralCoref the same way you usually manipulate a SpaCy document and it's annotations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mu'My sister has a dog. She loves him.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/anaconda/envs/azureml_py36/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36madd_pipe\u001b[0;34m(self, component, name, before, after, first, last)\u001b[0m\n\u001b[1;32m    303\u001b[0m                 \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomponent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE007\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipe_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbefore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mafter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlast\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mErrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mE006\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: [E007] 'neuralcoref' already exists in pipeline. Existing names: ['tagger', 'parser', 'ner', 'neuralcoref']"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References \n",
        "* https://pypi.org/project/rake-nltk/\n",
        "* https://huggingface.co/transformers/usage.html\n",
        "\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}